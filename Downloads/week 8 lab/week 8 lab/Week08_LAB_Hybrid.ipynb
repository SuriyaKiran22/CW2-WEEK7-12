{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Week 8: Data Pipeline & CRUD (SQL)\n",
    "## CST1510 ‚Äî Multi-Domain Intelligence Platform\n",
    "\n",
    "**Building Your Database Layer**\n",
    "\n",
    "<hr style=\"border:2px solid #0EA5E9\">\n",
    "\n",
    "### What You'll Build This Week\n",
    "\n",
    "This week, you're transitioning from **file-based storage** (`users.txt`) to a **professional database system** (SQLite). By the end of this lab, you will have:\n",
    "\n",
    "1.  **Migrated** your Week 7 users from `users.txt` ‚Üí SQLite database\n",
    "2.  **Created** database tables for all three domains (cyber_incidents, datasets_metadata, it_tickets)\n",
    "3.  **Loaded** CSV data using pandas\n",
    "4.  **Implemented** CRUD operations (Create, Read, Update, Delete) using Python functions\n",
    "5.  **Secured** your queries against SQL injection attacks\n",
    "6.  **Tested** your database with real-world queries\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "By completing this lab, you will:\n",
    "\n",
    "- Understand **why databases are better** than text files for data storage\n",
    "- Learn how to **connect to SQLite** using Python's built-in `sqlite3` module\n",
    "- Write **SQL CREATE TABLE** statements to define your data structure\n",
    "- Implement **CRUD operations** using Python functions\n",
    "- Use **parameterized queries** to prevent SQL injection\n",
    "- Load **CSV files** efficiently using pandas\n",
    "- Query your database to extract **meaningful insights**\n",
    "\n",
    "###  Beginner Tip\n",
    "\n",
    "Think of a database like a **super-powered Excel file** that:\n",
    "- Lives on disk (persists data)\n",
    "- Lets you search, add, update, and delete data **without reading the whole file**\n",
    "- Can link related data together (users ‚Üí incidents)\n",
    "- Protects against data corruption\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part0",
   "metadata": {},
   "source": [
    "## Part 0: Prerequisites & Setup\n",
    "\n",
    "### Step 0.1: Check Your Project Structure\n",
    "\n",
    "Before starting, make sure your project follows this structure:\n",
    "\n",
    "```\n",
    "CW2_M0123456_CST1510/\n",
    "‚îÇ\n",
    "‚îú‚îÄ app/\n",
    "‚îÇ  ‚îî‚îÄ data/              # Your database functions will go here\n",
    "‚îÇ\n",
    "‚îú‚îÄ DATA/                 # IMPORTANT: Uppercase DATA folder\n",
    "‚îÇ  ‚îú‚îÄ users.txt          # From Week 7\n",
    "‚îÇ  ‚îú‚îÄ cyber_incidents.csv\n",
    "‚îÇ  ‚îú‚îÄ datasets_metadata.csv\n",
    "‚îÇ  ‚îú‚îÄ it_tickets.csv\n",
    "‚îÇ  ‚îî‚îÄ intelligence_platform.db  # Will be created by your code\n",
    "‚îÇ\n",
    "‚îî‚îÄ requirements.txt\n",
    "```\n",
    "\n",
    "### Step 0.2: Install Required Libraries\n",
    "\n",
    "We'll use:\n",
    "- `sqlite3` ‚Üí **Built-in** to Python (no install needed!)\n",
    "- `pandas` ‚Üí For easy CSV loading\n",
    "- `bcrypt` ‚Üí For password hashing (from Week 7)\n",
    "\n",
    "Run this cell to install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "install",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\vingp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: bcrypt in c:\\users\\vingp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (5.0.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\vingp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\vingp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\vingp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\vingp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vingp\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "%pip install pandas bcrypt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports",
   "metadata": {},
   "source": [
    "### Step 0.3: Import Modules and Define Constants\n",
    "\n",
    "Let's import everything we need and set up our paths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "imports_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Imports successful!\n",
      " DATA folder: C:\\Users\\vingp\\Downloads\\week 8 lab\\week 8 lab\\DATA\n",
      " Database will be created at: C:\\Users\\vingp\\Downloads\\week 8 lab\\week 8 lab\\DATA\\intelligence_platform.db\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import bcrypt\n",
    "from pathlib import Path\n",
    "\n",
    "# Define paths\n",
    "DATA_DIR = Path(\"DATA\")\n",
    "DB_PATH = DATA_DIR / \"intelligence_platform.db\"\n",
    "\n",
    "# Create DATA folder if it doesn't exist\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\" Imports successful!\")\n",
    "print(f\" DATA folder: {DATA_DIR.resolve()}\")\n",
    "print(f\" Database will be created at: {DB_PATH.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "why_db",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 1: Why Move from Files to Databases?\n",
    "\n",
    "### Understanding the Problem\n",
    "\n",
    "In Week 7, you stored users in `users.txt`. This works for small projects, but has serious limitations:\n",
    "\n",
    "| **File Storage** (`users.txt`) | **Database** (`intelligence_platform.db`) |\n",
    "|--------------------------------|-------------------------------------------|\n",
    "| Slow search (must read entire file) | ‚ö° Fast search with SQL queries |\n",
    "| No relationships between data |  Link users to incidents, tickets, etc. |\n",
    "| Risk of corruption | ACID-safe (Atomicity, Consistency, Isolation, Durability) |\n",
    "| Manual parsing required | Powerful query language (SQL) |\n",
    "| Single-user access | Multi-user support |\n",
    "\n",
    "### Your Database Schema\n",
    "\n",
    "You'll create **4 tables**:\n",
    "\n",
    "1. **`users`** ‚Äî User accounts with authentication\n",
    "2. **`cyber_incidents`** ‚Äî Security incidents (your chosen domain)\n",
    "3. **`datasets_metadata`** ‚Äî Dataset information\n",
    "4. **`it_tickets`** ‚Äî IT support tickets\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2",
   "metadata": {},
   "source": [
    "## Part 2: Database Connection Functions\n",
    "\n",
    "### Step 2.1: Create Connection Function\n",
    "\n",
    "First, we need a function to connect to our database. This function will:\n",
    "- Create the database file if it doesn't exist\n",
    "- Return a connection object that we can use to run SQL commands\n",
    "\n",
    " **Beginner Tip**: Think of `conn` (connection) as a phone line to your database. You need it to send commands and get responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "connect_func",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_database(db_path=DB_PATH):\n",
    "    \"\"\"\n",
    "    Connect to the SQLite database.\n",
    "    Creates the database file if it doesn't exist.\n",
    "    \n",
    "    Args:\n",
    "        db_path: Path to the database file\n",
    "        \n",
    "    Returns:\n",
    "        sqlite3.Connection: Database connection object\n",
    "    \"\"\"\n",
    "    return sqlite3.connect(str(db_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Create Database Tables\n",
    "\n",
    "### Step 3.1: Create the `users` Table\n",
    "\n",
    "Let's start by creating a table for users. This table will store:\n",
    "- `id` ‚Äî Unique identifier (auto-incremented)\n",
    "- `username` ‚Äî User's login name (must be unique)\n",
    "- `password_hash` ‚Äî Hashed password (from bcrypt)\n",
    "- `role` ‚Äî User role (e.g., 'user', 'analyst', 'admin')\n",
    "\n",
    "üí° **Beginner Tip**: `CREATE TABLE IF NOT EXISTS` means \"create this table only if it doesn't already exist\". This prevents errors if you run the code multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "create_users_table",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_users_table(conn):\n",
    "    \"\"\"\n",
    "    Create the users table if it doesn't exist.\n",
    "    \n",
    "    This is a COMPLETE IMPLEMENTATION as an example.\n",
    "    Study this carefully before implementing the other tables!\n",
    "    \n",
    "    Args:\n",
    "        conn: Database connection object\n",
    "    \"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # SQL statement to create users table\n",
    "    create_table_sql = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS users (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        username TEXT NOT NULL UNIQUE,\n",
    "        password_hash TEXT NOT NULL,\n",
    "        role TEXT DEFAULT 'user',\n",
    "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "    )\n",
    "    \"\"\"\n",
    "    \n",
    "    cursor.execute(create_table_sql)\n",
    "    conn.commit()\n",
    "    print(\"‚úÖ Users table created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "create_domain_tables",
   "metadata": {},
   "source": [
    "### Step 3.2: Create Domain Tables\n",
    "\n",
    "Now let's create tables for your three domains. Each table will have columns matching your CSV files.\n",
    "\n",
    "#### Security Note: Foreign Keys\n",
    "\n",
    "Notice that `cyber_incidents` has a `FOREIGN KEY` that references `users(username)`. This creates a **relationship** between tables:\n",
    "- Each incident can be linked to the user who reported it\n",
    "- This is one of the key advantages of databases over text files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "create_domain_tables_code",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cyber_incidents_table(conn):\n",
    "    \"\"\"\n",
    "    Create the cyber_incidents table.\n",
    "    \"\"\"\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    sql = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS cyber_incidents (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        date TEXT,\n",
    "        incident_type TEXT,\n",
    "        severity TEXT,\n",
    "        status TEXT,\n",
    "        description TEXT,\n",
    "        reported_by TEXT,\n",
    "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "        FOREIGN KEY (reported_by) REFERENCES users(username)\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    cursor.execute(sql)\n",
    "    conn.commit()\n",
    "    print(\"‚úÖ cyber_incidents table created successfully!\")\n",
    "    pass\n",
    "\n",
    "\n",
    "def create_datasets_metadata_table(conn):\n",
    "    \"\"\"\n",
    "    Create the datasets_metadata table.\n",
    "    \"\"\"\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    sql = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS datasets_metadata (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        dataset_name TEXT NOT NULL,\n",
    "        category TEXT,\n",
    "        source TEXT,\n",
    "        last_updated TEXT,\n",
    "        record_count INTEGER,\n",
    "        file_size_mb REAL,\n",
    "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    cursor.execute(sql)\n",
    "    conn.commit()\n",
    "    print(\"‚úÖ datasets_metadata table created successfully!\")\n",
    "\n",
    "\n",
    "def create_it_tickets_table(conn):\n",
    "    \"\"\"\n",
    "    Create the it_tickets table.\n",
    "    \"\"\"\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    sql = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS it_tickets (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        ticket_id TEXT NOT NULL,\n",
    "        priority TEXT,\n",
    "        status TEXT,\n",
    "        category TEXT,\n",
    "        subject TEXT NOT NULL,\n",
    "        description TEXT,\n",
    "        created_date TEXT,\n",
    "        resolved_date TEXT,\n",
    "        assigned_to TEXT,\n",
    "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    cursor.execute(sql)\n",
    "    conn.commit()\n",
    "    print(\"‚úÖ it_tickets table created successfully!\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 4: Migrate Users from Week 7\n",
    "\n",
    "### Step 4.1: Understanding Migration\n",
    "\n",
    "**Migration** means copying data from an old format (text file) to a new format (database table).\n",
    "\n",
    "Your `users.txt` file from Week 7 has this format:\n",
    "```\n",
    "username,password_hash,role\n",
    "alice,$2b$12$...,analyst\n",
    "bob,$2b$12$...,user\n",
    "```\n",
    "\n",
    "We need to:\n",
    "1. Read each line from `users.txt`\n",
    "2. Parse the username, password_hash, and role\n",
    "3. INSERT each user into the `users` table\n",
    "\n",
    "### Step 4.2: Create Migration Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "migrate_users",
   "metadata": {},
   "outputs": [],
   "source": [
    "def migrate_users_from_file(conn, filepath=DATA_DIR / \"users.txt\"):\n",
    "    \"\"\"\n",
    "    Migrate users from users.txt to the database.\n",
    "    \n",
    "    This is a COMPLETE IMPLEMENTATION as an example.\n",
    "    \n",
    "    Args:\n",
    "        conn: Database connection\n",
    "        filepath: Path to users.txt file\n",
    "    \"\"\"\n",
    "    if not filepath.exists():\n",
    "        print(f\"‚ö†Ô∏è  File not found: {filepath}\")\n",
    "        print(\"   No users to migrate.\")\n",
    "        return\n",
    "    \n",
    "    cursor = conn.cursor()\n",
    "    migrated_count = 0\n",
    "    \n",
    "    with open(filepath, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            # Parse line: username,password_hash\n",
    "            parts = line.split(',')\n",
    "            if len(parts) >= 2:\n",
    "                username = parts[0]\n",
    "                password_hash = parts[1]\n",
    "                \n",
    "                # Insert user (ignore if already exists)\n",
    "                try:\n",
    "                    cursor.execute(\n",
    "                        \"INSERT OR IGNORE INTO users (username, password_hash, role) VALUES (?, ?, ?)\",\n",
    "                        (username, password_hash, 'user')\n",
    "                    )\n",
    "                    if cursor.rowcount > 0:\n",
    "                        migrated_count += 1\n",
    "                except sqlite3.Error as e:\n",
    "                    print(f\"Error migrating user {username}: {e}\")\n",
    "    \n",
    "    conn.commit()\n",
    "    print(f\"‚úÖ Migrated {migrated_count} users from {filepath.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verify_migration",
   "metadata": {},
   "source": [
    "### Step 4.3: Verify Migration\n",
    "\n",
    "Let's check that the users were actually inserted into the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4244c04f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "verify_migration_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Users in database:\n",
      "ID    Username        Role      \n",
      "-----------------------------------\n",
      "1     manan           user      \n",
      "2     test_user       user      \n",
      "10    suriya          user      \n",
      "\n",
      "Total users: 3\n"
     ]
    }
   ],
   "source": [
    "# Verify users were migrated\n",
    "conn = connect_database()\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Query all users\n",
    "cursor.execute(\"SELECT id, username, role FROM users\")\n",
    "users = cursor.fetchall()\n",
    "\n",
    "print(\" Users in database:\")\n",
    "print(f\"{'ID':<5} {'Username':<15} {'Role':<10}\")\n",
    "print(\"-\" * 35)\n",
    "for user in users:\n",
    "    print(f\"{user[0]:<5} {user[1]:<15} {user[2]:<10}\")\n",
    "\n",
    "print(f\"\\nTotal users: {len(users)}\")\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 5: Authentication Functions (Database-Backed)\n",
    "\n",
    "### Step 5.1: Register Function\n",
    "\n",
    "Now that users are in the database, we need to update our authentication to work with the database instead of `users.txt`.\n",
    "\n",
    "The `register()` function will:\n",
    "1. Check if username already exists\n",
    "2. Hash the password with bcrypt\n",
    "3. INSERT the new user into the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "register_func",
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_user(username, password, role=\"user\"):\n",
    "    \"\"\"\n",
    "    Register a new user in the database.\n",
    "    \n",
    "    This is a COMPLETE IMPLEMENTATION as an example.\n",
    "    \n",
    "    Args:\n",
    "        username: User's login name\n",
    "        password: Plain text password (will be hashed)\n",
    "        role: User role (default: 'user')\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (success: bool, message: str)\n",
    "    \"\"\"\n",
    "    conn = connect_database()\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Check if user already exists\n",
    "    cursor.execute(\"SELECT * FROM users WHERE username = ?\", (username,))\n",
    "    if cursor.fetchone():\n",
    "        conn.close()\n",
    "        return False, f\"Username '{username}' already exists.\"\n",
    "    \n",
    "    # Hash the password\n",
    "    password_bytes = password.encode('utf-8')\n",
    "    salt = bcrypt.gensalt()\n",
    "    hashed = bcrypt.hashpw(password_bytes, salt)\n",
    "    password_hash = hashed.decode('utf-8')\n",
    "    \n",
    "    # Insert new user\n",
    "    cursor.execute(\n",
    "        \"INSERT INTO users (username, password_hash, role) VALUES (?, ?, ?)\",\n",
    "        (username, password_hash, role)\n",
    "    )\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    \n",
    "    return True, f\"User '{username}' registered successfully!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "login_func_section",
   "metadata": {},
   "source": [
    "### Step 5.2: Login Function\n",
    "\n",
    "The `login()` function will:\n",
    "1. Look up the user in the database\n",
    "2. Retrieve their stored password hash\n",
    "3. Verify the provided password against the hash using bcrypt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "login_func",
   "metadata": {},
   "outputs": [],
   "source": [
    "def login_user(username, password):\n",
    "    \"\"\"\n",
    "    Authenticate a user against the database.\n",
    "    \n",
    "    This is a COMPLETE IMPLEMENTATION as an example.\n",
    "    \n",
    "    Args:\n",
    "        username: User's login name\n",
    "        password: Plain text password to verify\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (success: bool, message: str)\n",
    "    \"\"\"\n",
    "    conn = connect_database()\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Find user\n",
    "    cursor.execute(\"SELECT * FROM users WHERE username = ?\", (username,))\n",
    "    user = cursor.fetchone()\n",
    "    conn.close()\n",
    "    \n",
    "    if not user:\n",
    "        return False, \"Username not found.\"\n",
    "    \n",
    "    # Verify password (user[2] is password_hash column)\n",
    "    stored_hash = user[2]\n",
    "    password_bytes = password.encode('utf-8')\n",
    "    hash_bytes = stored_hash.encode('utf-8')\n",
    "    \n",
    "    if bcrypt.checkpw(password_bytes, hash_bytes):\n",
    "        return True, f\"Welcome, {username}!\"\n",
    "    else:\n",
    "        return False, \"Invalid password.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 6: Load CSV Data with Pandas\n",
    "\n",
    "### Step 6.1: Understanding Bulk Loading\n",
    "\n",
    "Now that your tables exist, you can load the provided CSV files. Pandas makes this incredibly easy with the `to_sql()` method.\n",
    "\n",
    " **Beginner Tip**: \n",
    "- `if_exists='append'` means \"add to existing data\"\n",
    "- `if_exists='replace'` means \"delete old data and insert new\"\n",
    "- `index=False` means \"don't save the DataFrame index as a column\"\n",
    "\n",
    "### Step 6.2: Create CSV Loading Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "load_csv_func",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_to_table(conn, csv_path, table_name):\n",
    "    \"\"\"\n",
    "    Load a CSV file into a database table using pandas.\n",
    "    Maps CSV columns to table schema for each domain.\n",
    "    \"\"\"\n",
    "    csv_path = Path(csv_path)\n",
    "\n",
    "    if not csv_path.exists():\n",
    "        print(f\"CSV not found: {csv_path}\")\n",
    "        return 0\n",
    "\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Map CSV columns to table schema based on table_name\n",
    "    if table_name == \"cyber_incidents\":\n",
    "        # CSV: Title, Date, Type, Category ‚Üí Table: description, date, incident_type, severity\n",
    "        df = df.rename(columns={\n",
    "            'Title': 'description',\n",
    "            'Date': 'date',\n",
    "            'Type': 'incident_type',\n",
    "            'Category': 'severity'\n",
    "        })\n",
    "        # Select only columns that exist in the table\n",
    "        df = df[['date', 'incident_type', 'severity', 'description']]\n",
    "        df['status'] = 'Open'  # Default status\n",
    "        df['reported_by'] = None  # No reporter info in CSV\n",
    "    \n",
    "    elif table_name == \"datasets_metadata\":\n",
    "        # CSV: name, source, category, size_mb ‚Üí Table: dataset_name, source, category, file_size_mb\n",
    "        df = df.rename(columns={\n",
    "            'name': 'dataset_name',\n",
    "            'size_mb': 'file_size_mb'\n",
    "        })\n",
    "        # Select only columns that exist in the table\n",
    "        df = df[['dataset_name', 'category', 'source', 'file_size_mb']]\n",
    "        df['last_updated'] = None  # No date info in CSV\n",
    "        df['record_count'] = None  # No record count in CSV\n",
    "    \n",
    "    elif table_name == \"it_tickets\":\n",
    "        # CSV already has matching columns, just drop 'id' (will be auto-generated)\n",
    "        df = df.drop(columns=['id'], errors='ignore')\n",
    "        # Ensure all required columns exist\n",
    "        required_cols = ['ticket_id', 'priority', 'status', 'category', 'subject', \n",
    "                        'description', 'created_date', 'resolved_date', 'assigned_to']\n",
    "        df = df[required_cols]\n",
    "\n",
    "    df.to_sql(\n",
    "        name=table_name,\n",
    "        con=conn,\n",
    "        if_exists='append',\n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    print(f\"‚úÖ Loaded {len(df)} rows into '{table_name}'\")\n",
    "\n",
    "    return len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 7: CRUD Operations\n",
    "\n",
    "### Understanding CRUD\n",
    "\n",
    "**CRUD** stands for the four basic operations you can perform on database data:\n",
    "\n",
    "| Operation | SQL Command | What It Does |\n",
    "|-----------|-------------|-------------|\n",
    "| **C**reate | `INSERT` | Add new records |\n",
    "| **R**ead | `SELECT` | Retrieve existing records |\n",
    "| **U**pdate | `UPDATE` | Modify existing records |\n",
    "| **D**elete | `DELETE` | Remove records |\n",
    "\n",
    "###  Security: Parameterized Queries\n",
    "\n",
    "**CRITICAL**: Always use `?` placeholders and pass values as a tuple to prevent SQL injection attacks!\n",
    "\n",
    " **NEVER DO THIS** (vulnerable to SQL injection):\n",
    "```python\n",
    "query = f\"SELECT * FROM users WHERE username = '{username}'\"\n",
    "```\n",
    "\n",
    " **ALWAYS DO THIS** (safe):\n",
    "```python\n",
    "query = \"SELECT * FROM users WHERE username = ?\"\n",
    "cursor.execute(query, (username,))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Step 7.1: CREATE ‚Äî Insert New Incident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "create_incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_incident(conn, date, incident_type, severity, status, description, reported_by=None):\n",
    "    \"\"\"\n",
    "    Insert a new incident into the database.\n",
    "    \"\"\"\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    sql = \"\"\"\n",
    "    INSERT INTO cyber_incidents \n",
    "    (date, incident_type, severity, status, description, reported_by)\n",
    "    VALUES (?, ?, ?, ?, ?, ?)\n",
    "    \"\"\"\n",
    "\n",
    "    cursor.execute(sql, (date, incident_type, severity, status, description, reported_by))\n",
    "    conn.commit()\n",
    "\n",
    "    return cursor.lastrowid\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "read_section",
   "metadata": {},
   "source": [
    "### Step 7.2: READ ‚Äî Query Incidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "read_incidents",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_incidents(conn):\n",
    "    \"\"\"\n",
    "    Return all cyber incidents as a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    query = \"SELECT * FROM cyber_incidents ORDER BY id DESC\"\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    return df\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "update_section",
   "metadata": {},
   "source": [
    "### Step 7.3: UPDATE ‚Äî Modify Incident Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "update_incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_incident_status(conn, incident_id, new_status):\n",
    "    \"\"\"\n",
    "    Update the status of an incident.\n",
    "    \"\"\"\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    sql = \"\"\"\n",
    "    UPDATE cyber_incidents\n",
    "    SET status = ?\n",
    "    WHERE id = ?\n",
    "    \"\"\"\n",
    "\n",
    "    cursor.execute(sql, (new_status, incident_id))\n",
    "    conn.commit()\n",
    "\n",
    "    return cursor.rowcount\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delete_section",
   "metadata": {},
   "source": [
    "### Step 7.4: DELETE ‚Äî Remove Incident\n",
    "\n",
    " **WARNING**: DELETE is permanent! Always use a WHERE clause to avoid deleting all rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "delete_incident",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_incident(conn, incident_id):\n",
    "    \"\"\"\n",
    "    Delete an incident by ID.\n",
    "    \"\"\"\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    sql = \"DELETE FROM cyber_incidents WHERE id = ?\"\n",
    "\n",
    "    cursor.execute(sql, (incident_id,))\n",
    "    conn.commit()\n",
    "\n",
    "    return cursor.rowcount\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 8: Analytical Queries (The Big 6) - OPTIONAL it couuld be done with pandas\n",
    "\n",
    "### Step 8.1: Using GROUP BY for Aggregation\n",
    "\n",
    "Let's use the **Big 6 SQL clauses** to extract insights from your data:\n",
    "\n",
    "1. **SELECT** ‚Äî Choose what columns to return\n",
    "2. **FROM** ‚Äî Specify the table\n",
    "3. **WHERE** ‚Äî Filter individual rows\n",
    "4. **GROUP BY** ‚Äî Group rows for aggregation\n",
    "5. **HAVING** ‚Äî Filter aggregated groups\n",
    "6. **ORDER BY** ‚Äî Sort the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "analytical_queries",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Incidents by Type:\n",
      "       incident_type  count\n",
      "0          Espionage   3366\n",
      "1               None    306\n",
      "2           Sabotage    207\n",
      "3  Denial of service    162\n",
      "4   Data destruction    126\n",
      "5    Financial Theft     63\n",
      "6             Doxing     54\n",
      "7         Defacement     45\n",
      "\n",
      " High Severity Incidents by Status:\n",
      "Empty DataFrame\n",
      "Columns: [status, count]\n",
      "Index: []\n",
      "\n",
      " Incident Types with Many Cases (>5):\n",
      "       incident_type  count\n",
      "0          Espionage   3366\n",
      "1               None    306\n",
      "2           Sabotage    207\n",
      "3  Denial of service    162\n",
      "4   Data destruction    126\n",
      "5    Financial Theft     63\n",
      "6             Doxing     54\n",
      "7         Defacement     45\n"
     ]
    }
   ],
   "source": [
    "def get_incidents_by_type_count(conn):\n",
    "    \"\"\"\n",
    "    Count incidents by type.\n",
    "    Uses: SELECT, FROM, GROUP BY, ORDER BY\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    SELECT incident_type, COUNT(*) as count\n",
    "    FROM cyber_incidents\n",
    "    GROUP BY incident_type\n",
    "    ORDER BY count DESC\n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    return df\n",
    "\n",
    "def get_high_severity_by_status(conn):\n",
    "    \"\"\"\n",
    "    Count high severity incidents by status.\n",
    "    Uses: SELECT, FROM, WHERE, GROUP BY, ORDER BY\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    SELECT status, COUNT(*) as count\n",
    "    FROM cyber_incidents\n",
    "    WHERE severity = 'High'\n",
    "    GROUP BY status\n",
    "    ORDER BY count DESC\n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    return df\n",
    "\n",
    "def get_incident_types_with_many_cases(conn, min_count=5):\n",
    "    \"\"\"\n",
    "    Find incident types with more than min_count cases.\n",
    "    Uses: SELECT, FROM, GROUP BY, HAVING, ORDER BY\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    SELECT incident_type, COUNT(*) as count\n",
    "    FROM cyber_incidents\n",
    "    GROUP BY incident_type\n",
    "    HAVING COUNT(*) > ?\n",
    "    ORDER BY count DESC\n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(query, conn, params=(min_count,))\n",
    "    return df\n",
    "\n",
    "# Test: Run analytical queries\n",
    "conn = connect_database()\n",
    "\n",
    "print(\"\\n Incidents by Type:\")\n",
    "df_by_type = get_incidents_by_type_count(conn)\n",
    "print(df_by_type)\n",
    "\n",
    "print(\"\\n High Severity Incidents by Status:\")\n",
    "df_high_severity = get_high_severity_by_status(conn)\n",
    "print(df_high_severity)\n",
    "\n",
    "print(\"\\n Incident Types with Many Cases (>5):\")\n",
    "df_many_cases = get_incident_types_with_many_cases(conn, min_count=5)\n",
    "print(df_many_cases)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 9: Complete Database Setup Script\n",
    "\n",
    "### Step 9.1: Create a Complete Setup Function\n",
    "\n",
    "Let's create a single function that sets up your entire database from scratch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "complete_setup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STARTING COMPLETE DATABASE SETUP\n",
      "============================================================\n",
      "\n",
      "[1/5] Connecting to database...\n",
      "‚úÖ Connected\n",
      "\n",
      "[2/5] Creating database tables...\n",
      "‚úÖ Users table created successfully!\n",
      "‚úÖ cyber_incidents table created successfully!\n",
      "‚úÖ datasets_metadata table created successfully!\n",
      "‚úÖ it_tickets table created successfully!\n",
      "\n",
      "[3/5] Migrating users from users.txt...\n",
      "‚ö†Ô∏è  File not found: DATA\\users.txt\n",
      "   No users to migrate.\n",
      "\n",
      "[4/5] Loading CSV data...\n",
      "‚úÖ Loaded 481 rows into 'cyber_incidents'\n",
      "‚úÖ Loaded 1000 rows into 'datasets_metadata'\n",
      "‚úÖ Loaded 1000 rows into 'it_tickets'\n",
      "\n",
      "[5/5] Verifying database setup...\n",
      "‚úÖ Tables in DB: ['users', 'sqlite_sequence', 'cyber_incidents', 'datasets_metadata', 'it_tickets']\n",
      "\n",
      "üìä Database Summary:\n",
      "Table                     Row Count      \n",
      "----------------------------------------\n",
      "users                     3              \n",
      "cyber_incidents           4810           \n",
      "datasets_metadata         10000          \n",
      "it_tickets                10000          \n",
      "\n",
      "============================================================\n",
      "‚úÖ DATABASE SETUP COMPLETE!\n",
      "============================================================\n",
      "\n",
      "üìÅ Database location: C:\\Users\\vingp\\Downloads\\week 8 lab\\week 8 lab\\DATA\\intelligence_platform.db\n",
      "üéâ You're ready for Week 9 (Streamlit web interface)!\n"
     ]
    }
   ],
   "source": [
    "def setup_database_complete():\n",
    "    \"\"\"\n",
    "    Complete database setup:\n",
    "    1. Connect to database\n",
    "    2. Create all tables\n",
    "    3. Migrate users from users.txt\n",
    "    4. Load CSV data for all domains\n",
    "    5. Verify setup\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STARTING COMPLETE DATABASE SETUP\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Step 1: Connect\n",
    "    print(\"\\n[1/5] Connecting to database...\")\n",
    "    conn = connect_database()\n",
    "    print(\"‚úÖ Connected\")\n",
    "    \n",
    "    # Step 2: Create tables\n",
    "    print(\"\\n[2/5] Creating database tables...\")\n",
    "    create_users_table(conn)\n",
    "    create_cyber_incidents_table(conn)\n",
    "    create_datasets_metadata_table(conn)\n",
    "    create_it_tickets_table(conn)\n",
    "    \n",
    "    # Step 3: Migrate users\n",
    "    print(\"\\n[3/5] Migrating users from users.txt...\")\n",
    "    migrate_users_from_file(conn)\n",
    "    \n",
    "    # Step 4: Load CSV data\n",
    "    print(\"\\n[4/5] Loading CSV data...\")\n",
    "    load_csv_to_table(conn, DATA_DIR / \"cyber_incidents.csv\", \"cyber_incidents\")\n",
    "    load_csv_to_table(conn, DATA_DIR / \"datasets_metadata.csv\", \"datasets_metadata\")\n",
    "    load_csv_to_table(conn, DATA_DIR / \"it_tickets.csv\", \"it_tickets\")\n",
    "    \n",
    "    # Step 5: Verify\n",
    "    print(\"\\n[5/5] Verifying database setup...\")\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n",
    "    tables_found = [r[0] for r in cursor.fetchall()]\n",
    "    print(\"‚úÖ Tables in DB:\", tables_found)\n",
    "    \n",
    "    # Count rows in each table\n",
    "    tables = ['users', 'cyber_incidents', 'datasets_metadata', 'it_tickets']\n",
    "    print(\"\\nüìä Database Summary:\")\n",
    "    print(f\"{'Table':<25} {'Row Count':<15}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for table in tables:\n",
    "        try:\n",
    "            cursor.execute(f\"SELECT COUNT(*) FROM {table}\")\n",
    "            count = cursor.fetchone()[0]\n",
    "            print(f\"{table:<25} {count:<15}\")\n",
    "        except sqlite3.OperationalError:\n",
    "            print(f\"{table:<25} {'N/A (not found)':<15}\")\n",
    "    \n",
    "    conn.close()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"‚úÖ DATABASE SETUP COMPLETE!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"\\nüìÅ Database location: {DB_PATH.resolve()}\")\n",
    "    print(\"üéâ You're ready for Week 9 (Streamlit web interface)!\")\n",
    "\n",
    "# Run the complete setup\n",
    "setup_database_complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part10",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 10: Testing & Verification\n",
    "\n",
    "### Step 10.1: Comprehensive Database Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "comprehensive_test",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üß™ RUNNING COMPREHENSIVE TESTS\n",
      "============================================================\n",
      "\n",
      "[TEST 1] Authentication\n",
      "  Register: ‚ùå Username 'test_user' already exists.\n",
      "  Login:    ‚úÖ Welcome, test_user!\n",
      "\n",
      "[TEST 2] CRUD Operations\n",
      "  Create: ‚úÖ Incident #4820 created\n",
      "  Read:    Found incident #4820\n",
      "  Update:  Status updated\n",
      "  Delete:  Incident deleted\n",
      "\n",
      "[TEST 3] Analytical Queries\n",
      "  By Type:     Found 8 incident types\n",
      "  High Severity: Found 0 status categories\n",
      "\n",
      "============================================================\n",
      "‚úÖ ALL TESTS PASSED!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "def run_comprehensive_tests():\n",
    "    \"\"\"\n",
    "    Run comprehensive tests on your database.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üß™ RUNNING COMPREHENSIVE TESTS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    conn = connect_database()\n",
    "    \n",
    "    # Test 1: Authentication\n",
    "    print(\"\\n[TEST 1] Authentication\")\n",
    "    success, msg = register_user(\"test_user\", \"TestPass123!\", \"user\")\n",
    "    print(f\"  Register: {'‚úÖ' if success else '‚ùå'} {msg}\")\n",
    "    \n",
    "    success, msg = login_user(\"test_user\", \"TestPass123!\")\n",
    "    print(f\"  Login:    {'‚úÖ' if success else '‚ùå'} {msg}\")\n",
    "    \n",
    "    # Test 2: CRUD Operations\n",
    "    print(\"\\n[TEST 2] CRUD Operations\")\n",
    "    \n",
    "    # Create\n",
    "    test_id = insert_incident(\n",
    "        conn,\n",
    "        \"2024-11-05\",\n",
    "        \"Test Incident\",\n",
    "        \"Low\",\n",
    "        \"Open\",\n",
    "        \"This is a test incident\",\n",
    "        \"test_user\"\n",
    "    )\n",
    "    print(f\"  Create: ‚úÖ Incident #{test_id} created\")\n",
    "    \n",
    "    # Read\n",
    "    df = pd.read_sql_query(\n",
    "        \"SELECT * FROM cyber_incidents WHERE id = ?\",\n",
    "        conn,\n",
    "        params=(test_id,)\n",
    "    )\n",
    "    print(f\"  Read:    Found incident #{test_id}\")\n",
    "    \n",
    "    # Update\n",
    "    update_incident_status(conn, test_id, \"Resolved\")\n",
    "    print(f\"  Update:  Status updated\")\n",
    "    \n",
    "    # Delete\n",
    "    delete_incident(conn, test_id)\n",
    "    print(f\"  Delete:  Incident deleted\")\n",
    "    \n",
    "    # Test 3: Analytical Queries\n",
    "    print(\"\\n[TEST 3] Analytical Queries\")\n",
    "    \n",
    "    df_by_type = get_incidents_by_type_count(conn)\n",
    "    print(f\"  By Type:     Found {len(df_by_type)} incident types\")\n",
    "    \n",
    "    df_high = get_high_severity_by_status(conn)\n",
    "    print(f\"  High Severity: Found {len(df_high)} status categories\")\n",
    "    \n",
    "    conn.close()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"‚úÖ ALL TESTS PASSED!\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# Run tests\n",
    "run_comprehensive_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  Congratulations!\n",
    "\n",
    "### What You've Accomplished\n",
    "\n",
    "You've successfully:\n",
    "\n",
    " **Migrated** from file-based storage to a professional SQLite database  \n",
    " **Created** a complete database schema with 4 tables  \n",
    " **Implemented** secure authentication with bcrypt  \n",
    " **Loaded** CSV data efficiently using pandas  \n",
    " **Built** CRUD functions for all database operations  \n",
    " **Secured** your queries against SQL injection  \n",
    " **Extracted** insights using analytical SQL queries  \n",
    "\n",
    "### Your Database Structure\n",
    "\n",
    "```\n",
    "intelligence_platform.db\n",
    "‚îú‚îÄ users                 (authentication)\n",
    "‚îú‚îÄ cyber_incidents       (security domain)\n",
    "‚îú‚îÄ datasets_metadata     (data domain)\n",
    "‚îî‚îÄ it_tickets            (IT domain)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "##  Next Steps: Week 9 Preview\n",
    "\n",
    "### What's Coming in Week 9\n",
    "\n",
    "Next week, you'll build a **Streamlit web interface** that uses your database:\n",
    "\n",
    "1. **Login Page** ‚Äî Use your `login_user()` function\n",
    "2. **Dashboard** ‚Äî Display incident statistics with charts\n",
    "3. **CRUD Forms** ‚Äî Interactive forms for creating/updating incidents\n",
    "4. **Visualizations** ‚Äî Use Plotly to create interactive charts\n",
    "5. **Session Management** ‚Äî Keep users logged in across pages\n",
    "\n",
    "### Preparing for Week 9\n",
    "\n",
    "Make sure your database is working correctly:\n",
    "-  All tables created\n",
    "-  Data loaded from CSVs\n",
    "-  CRUD operations tested\n",
    "-  Queries returning correct results\n",
    "\n",
    "---\n",
    "\n",
    "##  Submission Checklist\n",
    "\n",
    "Before submitting your Week 8 work, ensure you have:\n",
    "\n",
    "### Files to Submit\n",
    "\n",
    "- [ ] `app/data/db.py` ‚Äî Database connection functions\n",
    "- [ ] `app/data/schema.py` ‚Äî CREATE TABLE statements\n",
    "- [ ] `app/data/users.py` ‚Äî User CRUD functions\n",
    "- [ ] `app/data/incidents.py` ‚Äî Incident CRUD functions\n",
    "- [ ] `app/data/datasets.py` ‚Äî Dataset CRUD functions\n",
    "- [ ] `app/data/tickets.py` ‚Äî Ticket CRUD functions\n",
    "- [ ] `app/services/user_service.py` ‚Äî User migration function\n",
    "- [ ] `main.py` ‚Äî Demo script showing all CRUD operations\n",
    "- [ ] `DATA/intelligence_platform.db` ‚Äî Your populated database\n",
    "- [ ] `requirements.txt` ‚Äî Updated with pandas, bcrypt\n",
    "- [ ] `docs/README.md` ‚Äî Documentation with screenshots\n",
    "\n",
    "### Testing Checklist\n",
    "\n",
    "- [ ] Database connects successfully\n",
    "- [ ] All 4 tables created\n",
    "- [ ] Users migrated from users.txt\n",
    "- [ ] CSV data loaded\n",
    "- [ ] Registration works\n",
    "- [ ] Login works\n",
    "- [ ] Can create new incidents\n",
    "- [ ] Can read/query incidents\n",
    "- [ ] Can update incident status\n",
    "- [ ] Can delete incidents\n",
    "- [ ] Analytical queries return results\n",
    "- [ ] No SQL injection vulnerabilities (all queries use `?` placeholders)\n",
    "\n",
    "---\n",
    "\n",
    "##  Tips & Best Practices\n",
    "\n",
    "### Database Best Practices\n",
    "\n",
    "1. **Always close connections** when done\n",
    "2. **Use parameterized queries** (never string formatting)\n",
    "3. **Commit after writes** (INSERT, UPDATE, DELETE)\n",
    "4. **Use transactions** for multiple related operations\n",
    "5. **Index frequently queried columns** (for performance)\n",
    "\n",
    "### Debugging Tips\n",
    "\n",
    "If something doesn't work:\n",
    "\n",
    "1. **Check the error message** ‚Äî SQL errors are usually descriptive\n",
    "2. **Print your SQL** ‚Äî Use `print(query)` to see what's being executed\n",
    "3. **Test queries in DB Browser** ‚Äî Use a GUI tool to test SQL\n",
    "4. **Check data types** ‚Äî Make sure your Python types match SQL types\n",
    "5. **Verify file paths** ‚Äî Use absolute paths or check current directory\n",
    "\n",
    "### Common Errors\n",
    "\n",
    "| Error | Cause | Solution |\n",
    "|-------|-------|----------|\n",
    "| `table already exists` | Running CREATE TABLE twice | Use `IF NOT EXISTS` |\n",
    "| `UNIQUE constraint failed` | Duplicate username/ID | Check before INSERT |\n",
    "| `no such table` | Table not created | Run CREATE TABLE first |\n",
    "| `no such column` | Typo in column name | Check table schema |\n",
    "| `database is locked` | Connection not closed | Always close connections |\n",
    "\n",
    "---\n",
    "\n",
    "##  Additional Resources\n",
    "\n",
    "### SQLite Documentation\n",
    "- [SQLite Official Docs](https://www.sqlite.org/docs.html)\n",
    "- [Python sqlite3 Module](https://docs.python.org/3/library/sqlite3.html)\n",
    "\n",
    "### SQL Learning Resources\n",
    "- [W3Schools SQL Tutorial](https://www.w3schools.com/sql/)\n",
    "- [SQLite Tutorial](https://www.sqlitetutorial.net/)\n",
    "\n",
    "### Tools\n",
    "- [DB Browser for SQLite](https://sqlitebrowser.org/) ‚Äî GUI for viewing/editing databases\n",
    "- [SQLite Viewer (VS Code Extension)](https://marketplace.visualstudio.com/items?itemName=alexcvzz.vscode-sqlite)\n",
    "\n",
    "---\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
